{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgpath</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21590</th>\n",
       "      <td>./animals/raw-img\\ragno\\OIP-gXkw8eyrnY19blMCGd...</td>\n",
       "      <td>ragno</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>./animals/raw-img\\cavallo\\OIP-me7nmDgO_QwDyzj7...</td>\n",
       "      <td>cavallo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>./animals/raw-img\\cavallo\\OIP-iyfTWYmICwO9-0ra...</td>\n",
       "      <td>cavallo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22295</th>\n",
       "      <td>./animals/raw-img\\ragno\\OIP-llpwljKwZtTrn4PTEp...</td>\n",
       "      <td>ragno</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032</th>\n",
       "      <td>./animals/raw-img\\ragno\\OIP-1whi6SMIAAR3Ajug6S...</td>\n",
       "      <td>ragno</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 imgpath   labels  \\\n",
       "21590  ./animals/raw-img\\ragno\\OIP-gXkw8eyrnY19blMCGd...    ragno   \n",
       "6337   ./animals/raw-img\\cavallo\\OIP-me7nmDgO_QwDyzj7...  cavallo   \n",
       "6032   ./animals/raw-img\\cavallo\\OIP-iyfTWYmICwO9-0ra...  cavallo   \n",
       "22295  ./animals/raw-img\\ragno\\OIP-llpwljKwZtTrn4PTEp...    ragno   \n",
       "20032  ./animals/raw-img\\ragno\\OIP-1whi6SMIAAR3Ajug6S...    ragno   \n",
       "\n",
       "       encoded_labels  \n",
       "21590               8  \n",
       "6337                1  \n",
       "6032                1  \n",
       "22295               8  \n",
       "20032               8  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './animals/raw-img'\n",
    "classes = os.listdir(path)\n",
    "data = {\"imgpath\": [], \"labels\": [] }\n",
    "\n",
    "for classe in classes:\n",
    "    imagesclass = os.path.join(path, classe)\n",
    "    filelist = os.listdir(imagesclass)\n",
    "    for image in filelist:\n",
    "       data[\"imgpath\"].append(os.path.join(imagesclass,image))\n",
    "       data[\"labels\"].append(classe)\n",
    "    \n",
    "dataset = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "lb = LabelEncoder()\n",
    "dataset['encoded_labels'] = lb.fit_transform(dataset['labels'])\n",
    "dataset.sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTreino, datasetTemp = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "datasetTeste, datasetValid = train_test_split(datasetTemp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18325 validated image filenames belonging to 10 classes.\n",
      "Found 3927 validated image filenames belonging to 10 classes.\n",
      "Found 3927 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
    "    rescale = 1. /255,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Create a bottleneck file\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "\n",
    "# Image dimension\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Split the data into three categories\n",
    "\n",
    "# 1_Training Data\n",
    "train_images = generator.flow_from_dataframe(\n",
    "    dataframe=datasetTreino,\n",
    "    x_col='imgpath',\n",
    "    y_col='labels',\n",
    "    target_size=(img_width, img_height),\n",
    "    class_size='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 2_Validation Data\n",
    "val_images = generator.flow_from_dataframe(\n",
    "    dataframe=datasetValid,\n",
    "    x_col='imgpath',\n",
    "    y_col='labels',\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# 3_Test Data\n",
    "test_images = generator.flow_from_dataframe(\n",
    "    dataframe=datasetTeste,\n",
    "    x_col='imgpath',\n",
    "    y_col='labels',\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "Epoch 1/10\n",
      "916/916 [==============================] - 1261s 1s/step - loss: 0.2477 - accuracy: 0.9225 - val_loss: 0.1699 - val_accuracy: 0.9501\n",
      "Epoch 2/10\n",
      "916/916 [==============================] - 1185s 1s/step - loss: 0.1463 - accuracy: 0.9548 - val_loss: 0.1669 - val_accuracy: 0.9544\n",
      "Epoch 3/10\n",
      "916/916 [==============================] - 1181s 1s/step - loss: 0.1251 - accuracy: 0.9607 - val_loss: 0.1731 - val_accuracy: 0.9524\n",
      "Epoch 4/10\n",
      "916/916 [==============================] - 1199s 1s/step - loss: 0.1084 - accuracy: 0.9657 - val_loss: 0.1984 - val_accuracy: 0.9503\n",
      "Epoch 5/10\n",
      "916/916 [==============================] - 1192s 1s/step - loss: 0.0953 - accuracy: 0.9704 - val_loss: 0.1837 - val_accuracy: 0.9539\n",
      "Epoch 6/10\n",
      "916/916 [==============================] - 1199s 1s/step - loss: 0.0960 - accuracy: 0.9709 - val_loss: 0.2108 - val_accuracy: 0.9496\n",
      "Epoch 7/10\n",
      "916/916 [==============================] - 1186s 1s/step - loss: 0.0854 - accuracy: 0.9738 - val_loss: 0.2034 - val_accuracy: 0.9519\n",
      "Epoch 8/10\n",
      "916/916 [==============================] - 1189s 1s/step - loss: 0.0765 - accuracy: 0.9750 - val_loss: 0.2003 - val_accuracy: 0.9521\n",
      "Epoch 9/10\n",
      "916/916 [==============================] - 1189s 1s/step - loss: 0.0779 - accuracy: 0.9749 - val_loss: 0.2393 - val_accuracy: 0.9453\n",
      "Epoch 10/10\n",
      "916/916 [==============================] - 1204s 1s/step - loss: 0.0727 - accuracy: 0.9774 - val_loss: 0.2116 - val_accuracy: 0.9537\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "\n",
    "feature_extractor_layer = hub.KerasLayer(resnet_url,\n",
    "                                           trainable=False, \n",
    "                                           name='feature_extraction_layer',\n",
    "                                           input_shape=(224, 224, 3))\n",
    "\n",
    "resnet_model = tf.keras.Sequential([\n",
    "    feature_extractor_layer, \n",
    "    layers.Dense(10, activation='softmax', name='output_layer')  \n",
    "  ])\n",
    "\n",
    "resnet_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "STEP_SIZE_TRAIN=train_images.n//train_images.batch_size\n",
    "\n",
    "resnet_model_history = resnet_model.fit(train_images, \n",
    "                        epochs=10,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        validation_data=val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 197/3927 [>.............................] - ETA: 1:07:36WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3927 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3927 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3927/3927 [==============================] - 215s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_images.n\n",
    "test_images.reset() \n",
    "pred=resnet_model.predict(test_images, steps=STEP_SIZE_TEST, verbose=1)\n",
    "\n",
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 217s 1s/step - loss: 0.1800 - accuracy: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17995303869247437, 0.9516170024871826]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.evaluate(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3927,)\n",
      "(3927,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9590017825311943"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(test_images.labels)\n",
    "print(x.shape)\n",
    "print(predicted_class_indices.shape)\n",
    "accuracy_score(x, predicted_class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visaocomputacional",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
